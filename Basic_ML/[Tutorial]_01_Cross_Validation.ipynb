{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Tutorial] 01. Cross-Validation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN4Zmm5tv4n1ItJkbPFfjSs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Steve-YJ/Explore-Kaggle/blob/master/%5BTutorial%5D_01_Cross_Validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_t_9oONh91Wv",
        "colab_type": "text"
      },
      "source": [
        "## Reference\n",
        "\n",
        "[Machine Learning Mastery](https://machinelearningmastery.com/k-fold-cross-validation/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNEkl7GS9V0G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "49156db7-a270-4628-94bf-6fc09d0253b2"
      },
      "source": [
        "# worked Example\n",
        "\n",
        "simple = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
        "simple"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1, 0.2, 0.3, 0.4, 0.5, 0.6]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZJdDctn-imi",
        "colab_type": "text"
      },
      "source": [
        "Three models are trained and evaluated with each fold given a chance to be the held out test set.\n",
        "\n",
        "For example:\n",
        "\n",
        "* Model1: Trained on Fold1 + Fold2, Tested on Fold3\n",
        "* Model2: Trained on Fold2 + Fold3, Tested on Fold1\n",
        "* Model3: Trained on Fold1 + Fold3, Tested on Fold2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P25asm3h-pN3",
        "colab_type": "text"
      },
      "source": [
        "## Cross-Validation API\n",
        "* The <code>scikit-learn</code> library provides an implementation that will split a given data sample up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8aIeqxz-FAO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "661e4a66-db2f-4b0c-ba20-0c9039d78363"
      },
      "source": [
        "# scikit-learn k-fold cross-validation\n",
        "from numpy import array\n",
        "from sklearn.model_selection import KFold  # sklearn model_selection에서 KFold Import\n",
        "\n",
        "# data sample\n",
        "data = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6])\n",
        "\n",
        "# prepare cross validation\n",
        "kfold = KFold(3, True, 1)\n",
        "\n",
        "# enumerate splits\n",
        "for train, test in kfold.split(data):\n",
        "    print('train: %s, test: %s' % (data[train], data[test]))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: [0.1 0.4 0.5 0.6], test: [0.2 0.3]\n",
            "train: [0.2 0.3 0.4 0.6], test: [0.1 0.5]\n",
            "train: [0.1 0.2 0.3 0.5], test: [0.4 0.6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HoB0_RMASlA",
        "colab_type": "text"
      },
      "source": [
        "## Variations on Cross-Validation\n",
        "* There are a number of variations on the k-fold cross validation procedure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7HYwp1eAo8F",
        "colab_type": "text"
      },
      "source": [
        "* Train/Test Split: Taken to one extreme, k may be set to 2 (not 1) such that a single train/test split is created to evaluate the model.\n",
        "* LOOCV: Taken to another extreme, k may be set to the total number of observations in the dataset such that each observation is given a chance to be the held out of the dataset. This is called leave-one-out cross-validation, or LOOCV for short.\n",
        "* Stratified: The splitting of data into folds may be governed by criteria such as ensuring that each fold has the same proportion of observations with a given categorical value, such as the class outcome value. This is called stratified cross-validation.\n",
        "* Repeated: This is where the k-fold cross-validation procedure is repeated n times, where importantly, the data sample is shuffled prior to each repetition, which results in a different split of the sample.\n",
        "* Nested: This is where k-fold cross-validation is performed within each fold of cross-validation, often to perform hyperparameter tuning during model evaluation. This is called nested cross-validation or double cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK5ypMjO_Ym-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}